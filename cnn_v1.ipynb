{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Notebook basiert auf diesem Turoial:\n",
    "# https://www.analyticsvidhya.com/blog/2019/09/step-by-step-deep-learning-tutorial-video-classification-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2     # for capturing videos\n",
    "import math   # for mathematical operations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "#from skimage.transform import resize   # for resizing images\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing training labels\n",
    "labels_df = pd.read_csv('material/labels.csv', sep=';')\n",
    "\n",
    "# deleting videos with changing perspectives\n",
    "labels_df = labels_df.drop(labels_df.loc[labels_df['Wechsel'] == True].index)\n",
    "labels_df = labels_df.reset_index()\n",
    "\n",
    "# droping unused columns:\n",
    "labels_df.drop(columns=['index','Wechsel','ID'], inplace=True)\n",
    "labels_df.rename(columns={'Camera Position (Side/Front/Upwards/Downwards)':'labels'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:43<00:00,  2.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# storing the frames from training videos\n",
    "for i in tqdm(range(labels_df.shape[0])):\n",
    "    count = 0\n",
    "    videoFile = labels_df['NameOfFile'][i]\n",
    "    cap = cv2.VideoCapture('material/raw_training_videos/'+videoFile)   # capturing the video from the given path\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    #print(frameRate)\n",
    "    x=1\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1) #current frame number\n",
    "        #print(frameId)\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        #if (frameId % math.floor(frameRate) == 0):\n",
    "            # storing the frames in a new folder named train_frames\n",
    "        else:\n",
    "            filename ='material/train_frames/' + videoFile +\"_frame%d.jpg\" % count;count+=1\n",
    "            cv2.imwrite(filename, frame)\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8300/8300 [00:01<00:00, 5651.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# getting the names of all the images\n",
    "images = glob(\"material/train_frames/*.jpg\")\n",
    "train_image = []\n",
    "train_class = []\n",
    "for i in tqdm(range(len(images))):\n",
    "    # creating the image name\n",
    "    name = images[i].split('/')[2].split('_f')[0]\n",
    "    #print(name)\n",
    "    train_image.append(images[i].split('/')[2])\n",
    "    # creating the class of image\n",
    "    train_class.append(labels_df['labels'].loc[labels_df['NameOfFile'] == name].values[0])\n",
    "    \n",
    "# storing the images and their class in a dataframe\n",
    "train_data = pd.DataFrame()\n",
    "train_data['image'] = train_image\n",
    "train_data['class'] = train_class\n",
    "\n",
    "# converting the dataframe into csv file \n",
    "train_data.to_csv('material/train_frames.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv with labels for frames\n",
    "train = pd.read_csv('material/train_frames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8300/8300 [02:35<00:00, 53.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8300, 480, 640, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in all the frames and saving them to a numpy array\n",
    "\n",
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the image size (480, 640, 3)\n",
    "    '''\n",
    "    TO DO:\n",
    "    finde heraus was die ideale input größe der bilder ist. \n",
    "    '''\n",
    "    img = image.load_img('material/train_frames/'+train['image'][i], target_size=(480, 640, 3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    '''\n",
    "    TO DO:\n",
    "    finde heraus was die optimale normalisierung der Bild daten ist\n",
    "    '''\n",
    "    img = img/480\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)\n",
    "    \n",
    "# converting the list to numpy array\n",
    "X = np.array(train_image)\n",
    "\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and test set\n",
    "\n",
    "# separating the target\n",
    "y = train['class']\n",
    "\n",
    "# creating the training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummies of target variable for train and validation set\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the architecture of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the base model of pre-trained VGG16 model\n",
    "'''\n",
    "TO DO: \n",
    "finde heraus wie ein Model performt, welches von \"scratch\" creiert wird\n",
    "'''\n",
    "base_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(base_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 1min 11s, total: 2min 20s\n",
      "Wall time: 1min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6640, 15, 20, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# extracting features for training frames\n",
    "\n",
    "X_train = base_model.predict(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.4 s, sys: 10.1 s, total: 31.6 s\n",
      "Wall time: 24.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1660, 15, 20, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# extracting features for validation frames\n",
    "\n",
    "X_test = base_model.predict(X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "\n",
    "X_train = X_train.reshape(6640, 15*20*512)\n",
    "X_test = X_test.reshape(1660, 15*20*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 s, sys: 534 ms, total: 1.54 s\n",
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# normalizing the pixel values\n",
    "\n",
    "max = X_train.max()\n",
    "X_train = X_train/max\n",
    "X_test = X_test/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6640, 153600)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of images\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(153600,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              157287424 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 157,976,964\n",
      "Trainable params: 157,976,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('weight_v1.1.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model wird hier trainiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "52/52 [==============================] - 4s 86ms/step - loss: 1.1858 - accuracy: 0.5373 - val_loss: 0.4648 - val_accuracy: 0.8765\n",
      "Epoch 2/25\n",
      "52/52 [==============================] - 18s 353ms/step - loss: 0.2581 - accuracy: 0.9059 - val_loss: 0.0820 - val_accuracy: 0.9608\n",
      "Epoch 3/25\n",
      "52/52 [==============================] - 18s 354ms/step - loss: 0.0926 - accuracy: 0.9592 - val_loss: 0.0364 - val_accuracy: 0.9958\n",
      "Epoch 4/25\n",
      "52/52 [==============================] - 18s 354ms/step - loss: 0.0608 - accuracy: 0.9801 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 5/25\n",
      "52/52 [==============================] - 18s 354ms/step - loss: 0.0446 - accuracy: 0.9854 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 6/25\n",
      "52/52 [==============================] - 18s 354ms/step - loss: 0.0299 - accuracy: 0.9922 - val_loss: 8.1736e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/25\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 0.0750 - accuracy: 0.9780 - val_loss: 0.0080 - val_accuracy: 0.9988\n",
      "Epoch 8/25\n",
      "52/52 [==============================] - 2s 46ms/step - loss: 0.0506 - accuracy: 0.9810 - val_loss: 9.2331e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/25\n",
      "52/52 [==============================] - 19s 358ms/step - loss: 0.0341 - accuracy: 0.9878 - val_loss: 2.6850e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/25\n",
      "52/52 [==============================] - 2s 46ms/step - loss: 0.0313 - accuracy: 0.9886 - val_loss: 3.3026e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/25\n",
      "52/52 [==============================] - 18s 352ms/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 1.0415e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/25\n",
      "52/52 [==============================] - 18s 354ms/step - loss: 0.0325 - accuracy: 0.9878 - val_loss: 2.9427e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/25\n",
      "52/52 [==============================] - 18s 353ms/step - loss: 0.0281 - accuracy: 0.9904 - val_loss: 2.7516e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/25\n",
      "52/52 [==============================] - 2s 46ms/step - loss: 0.0264 - accuracy: 0.9925 - val_loss: 7.3958e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/25\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 3.7750e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/25\n",
      "52/52 [==============================] - 2s 46ms/step - loss: 0.0406 - accuracy: 0.9851 - val_loss: 1.0967e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/25\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 0.0266 - accuracy: 0.9907 - val_loss: 1.9003e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/25\n",
      "52/52 [==============================] - 19s 363ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 8.2343e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/25\n",
      "52/52 [==============================] - 18s 353ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 3.5590e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 1.8295e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "52/52 [==============================] - 2s 46ms/step - loss: 0.0348 - accuracy: 0.9893 - val_loss: 1.5925e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/25\n",
      "52/52 [==============================] - 2s 46ms/step - loss: 0.0285 - accuracy: 0.9913 - val_loss: 6.6830e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 6.7109e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "52/52 [==============================] - 2s 47ms/step - loss: 0.0285 - accuracy: 0.9904 - val_loss: 1.2482e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "52/52 [==============================] - 2s 45ms/step - loss: 0.0268 - accuracy: 0.9899 - val_loss: 6.0336e-06 - val_accuracy: 1.0000\n",
      "CPU times: user 2min 53s, sys: 1min 44s, total: 4min 37s\n",
      "Wall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training the model \n",
    "\n",
    "version1 = model.fit(X_train, y_train, epochs=25, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAArtUlEQVR4nO3deZhcdZ3v8fe3uqt6qU6v6SSdTkICgmQhJNCyiCwOqAEVRFmvqHBH4nj1os+oz6AzKuPVqzN6He7cQQVGHJmrIKJovEZxdEBEAQkQQhaWAIF01k6nl/SW3r73j3O6U9VdvSVdXZ2cz+t5+qlT55w69T1dSX36/H7n/I65OyIiIgNiuS5ARESmFwWDiIikUTCIiEgaBYOIiKRRMIiISBoFg4iIpFEwiIyTmf2bmX15nOtuM7OLjnQ7IrmgYBARkTQKBhERSaNgkGNK2ITzGTPbYGbtZvZdM5ttZr8yswNm9lszq0hZ/1Iz22RmzWb2sJktTlm20syeDl/3I6BwyHu9y8zWh6/9k5ktP8yabzSzrWa238zWmNnccL6Z2T+Z2V4zazWz58xsWbjsEjPbHNa2w8w+fVi/MJEMFAxyLHof8DbgJODdwK+AzwHVBP/mbwIws5OAe4BPhsvWAr8ws4SZJYCfAf8OVAI/DrdL+NqVwF3AR4Aq4HZgjZkVTKRQM/sL4KvAVUAN8Bpwb7j47cB54X6Uhes0hsu+C3zE3WcAy4D/nMj7ioxGwSDHov/j7nvcfQfwB+AJd3/G3buAB4CV4XpXA7909/9w9x7gG0AR8GbgLCAO3OruPe5+P/BkynusBm539yfcvc/dvw8cDF83Ee8H7nL3p939IPBZ4GwzWwj0ADOAkwFz9y3uvit8XQ+wxMxK3b3J3Z+e4PuKjEjBIMeiPSnTnRmel4TTcwn+QgfA3fuB7UBtuGyHp48y+VrK9HHAp8JmpGYzawbmh6+biKE1tBEcFdS6+38C/wLcBuw1szvMrDRc9X3AJcBrZvZ7Mzt7gu8rMiIFg0TZToIveCBo0yf4ct8B7AJqw3kDFqRMbwe+4u7lKT/F7n7PEdaQJGia2gHg7v/s7qcDSwialD4Tzn/S3S8DZhE0ed03wfcVGZGCQaLsPuCdZnahmcWBTxE0B/0JeAzoBW4ys7iZvRc4I+W1dwJ/ZWZnhp3ESTN7p5nNmGAN9wA3mNmKsH/ifxI0fW0zszeF248D7UAX0B/2gbzfzMrCJrBWoP8Ifg8iaRQMElnu/gJwHfB/gH0EHdXvdvdud+8G3gtcD+wn6I/4acpr1wE3EjT1NAFbw3UnWsNvgc8DPyE4SjkBuCZcXEoQQE0EzU2NwNfDZR8AtplZK/BXBH0VIpPCdKMeERFJpSMGERFJo2AQEZE0CgYREUmjYBARkTT5uS5gombOnOkLFy7MdRkiIkeVp556ap+7V49n3aMuGBYuXMi6detyXYaIyFHFzF4be62AmpJERCSNgkFERNIoGEREJE3W+hjM7C7gXcBed1+WYfn7gb8BDDgAfNTdn81WPSIyPfX09FBfX09XV1euSzkmFBYWMm/ePOLx+GFvI5udz/9GMI7M3SMsfxU4392bzOxi4A7gzCzWIyLTUH19PTNmzGDhwoWkD2YrE+XuNDY2Ul9fz6JFiw57O1lrSnL3RwgGHxtp+Z/cvSl8+jgwL1u1iMj01dXVRVVVlUJhEpgZVVVVR3z0NV36GP6S4PaLGZnZajNbZ2brGhoaprAsEZkKCoXJMxm/y5wHg5m9lSAY/makddz9Dnevc/e66upxXZ8xzAu7D/D1B5+nqb37MCsVEYmGnAaDmS0H/hW4zN0bx1r/SLy6r53bHnqZHc2d2XwbETnKNDc3861vfWvCr7vkkktobm6e/IKmgZwFg5ktILjxyQfc/cVsv19VSQKA/TpiEJEUIwVDb2/vqK9bu3Yt5eXlWaoqt7J5uuo9wAXATDOrB74IxAHc/TvAFwjubfutsE2s193rslVPZVLBICLD3Xzzzbz88susWLGCeDxOYWEhFRUVPP/887z44ou85z3vYfv27XR1dfGJT3yC1atXA4eG52lra+Piiy/mLW95C3/605+ora3l5z//OUVFRTnes8OXtWBw92vHWP5h4MPZev+hqsJgaFQwiExbf/+LTWze2Tqp21wyt5QvvnvpiMu/9rWvsXHjRtavX8/DDz/MO9/5TjZu3Dh4uuddd91FZWUlnZ2dvOlNb+J973sfVVVVadt46aWXuOeee7jzzju56qqr+MlPfsJ11103qfsxlY66QfQOV2lhnLyYsb/9YK5LEZFp7Iwzzki7BuCf//mfeeCBBwDYvn07L7300rBgWLRoEStWrADg9NNPZ9u2bVNVblZEJhhiMaOiOKGmJJFpbLS/7KdKMpkcnH744Yf57W9/y2OPPUZxcTEXXHBBxmsECgoKBqfz8vLo7Dy6T3LJ+emqU6kqmaCxTcEgIofMmDGDAwcOZFzW0tJCRUUFxcXFPP/88zz++ONTXF1uROaIAYIOaB0xiEiqqqoqzjnnHJYtW0ZRURGzZ88eXLZq1Sq+853vsHjxYt74xjdy1lln5bDSqROtYChJsGWSO7ZE5Oj3wx/+MOP8goICfvWrzIMyDPQjzJw5k40bNw7O//SnPz3p9U216DUl6YhBRGRUkQqGymSCls4eevr6c12KiMi0FalgGLiWoalDRw0iIiOJVDBUJoNTytQBLSIysogFQzgshk5ZFREZUaSCYWAgPXVAi4iMLFLBoIH0RORIlZSUALBz506uuOKKjOtccMEFrFu3btTt3HrrrXR0dAw+n07DeEcqGCqKE5jpiEFEjtzcuXO5//77D/v1Q4NhOg3jHalgyIsZ5UVxDaQnIoNuvvlmbrvttsHnt9xyC1/+8pe58MILOe200zjllFP4+c9/Pux127ZtY9myZQB0dnZyzTXXsHjxYi6//PK0sZI++tGPUldXx9KlS/niF78IBAPz7dy5k7e+9a289a1vBYJhvPft2wfAN7/5TZYtW8ayZcu49dZbB99v8eLF3HjjjSxdupS3v/3tWRuTKVJXPoOGxRCZ1n51M+x+bnK3OecUuPhrIy6++uqr+eQnP8nHPvYxAO677z4efPBBbrrpJkpLS9m3bx9nnXUWl1566Yj3U/72t79NcXExW7ZsYcOGDZx22mmDy77yla9QWVlJX18fF154IRs2bOCmm27im9/8Jg899BAzZ85M29ZTTz3F9773PZ544gncnTPPPJPzzz+fioqKKRveO1JHDABVyQINpCcig1auXMnevXvZuXMnzz77LBUVFcyZM4fPfe5zLF++nIsuuogdO3awZ8+eEbfxyCOPDH5BL1++nOXLlw8uu++++zjttNNYuXIlmzZtYvPmzaPW8+ijj3L55ZeTTCYpKSnhve99L3/4wx+AqRveO5JHDC83tOW6DBHJZJS/7LPpyiuv5P7772f37t1cffXV/OAHP6ChoYGnnnqKeDzOwoULMw63PZZXX32Vb3zjGzz55JNUVFRw/fXXH9Z2BkzV8N6RO2KoLFFTkoiku/rqq7n33nu5//77ufLKK2lpaWHWrFnE43EeeughXnvttVFff9555w0OxLdx40Y2bNgAQGtrK8lkkrKyMvbs2ZM2IN9Iw32fe+65/OxnP6Ojo4P29nYeeOABzj333Enc27FF7oihKpmgqaOb/n4nFsvcXigi0bJ06VIOHDhAbW0tNTU1vP/97+fd7343p5xyCnV1dZx88smjvv6jH/0oN9xwA4sXL2bx4sWcfvrpAJx66qmsXLmSk08+mfnz53POOecMvmb16tWsWrWKuXPn8tBDDw3OP+2007j++us544wzAPjwhz/MypUrp/SucObuU/Zmk6Gurs7HOj94NN/746v8/S828/Tn3zZ4XYOI5M6WLVtYvHhxrss4pmT6nZrZU+5eN57XR68pafAiN52yKiKSSeSCoSocSE9nJomIZBa5YNCwGCLTz9HWpD2dTcbvMnLBoIH0RKaXwsJCGhsbFQ6TwN1pbGyksLDwiLaTtbOSzOwu4F3AXndflmG5Af8buAToAK5396ezVc+AimIdMYhMJ/PmzaO+vp6GhoZcl3JMKCwsZN68eUe0jWyervpvwL8Ad4+w/GLgxPDnTODb4WNWJfJjzCjMVzCITBPxeJxFixblugxJkbWmJHd/BNg/yiqXAXd74HGg3MxqslVPqqpkQk1JIiIjyGUfQy2wPeV5fThvGDNbbWbrzGzdZBxuBgPp6XRVEZFMjorOZ3e/w93r3L2uurr6iLdXqYH0RERGlMtg2AHMT3k+L5yXdVUaeltEZES5DIY1wActcBbQ4u67puKNK0uC8ZJ0epyIyHDZPF31HuACYKaZ1QNfBOIA7v4dYC3BqapbCU5XvSFbtQxVlUzQ0+e0dvVSVhSfqrcVETkqZC0Y3P3aMZY78LFsvf9oUq9+VjCIiKQ7KjqfJ1uFBtITERlRJIOhKgwGnZkkIjJcJINBA+mJiIwsksEwOPS2gkFEZJhIBkNRIo+ieJ6OGEREMohkMMDAsBgKBhGRoSIbDFUlGkhPRCSTyAaDBtITEcks2sGg01VFRIaJbDAM3JNB4yWJiKSLbDBUJgs42NtPR3dfrksREZlWIhsMVbrITUQko8gGw8DVzzozSUQkXXSDoUQD6YmIZBLZYNBAeiIimUU2GDSQnohIZpENhpKCfBJ5MQWDiMgQkQ0GM6MyqWExRESGimwwgAbSExHJJNLBoIH0RESGi3QwaCA9EZHhFAw6XVVEJE2kg6EqmaC9u4+uHo2XJCIyINLBUBne+1kd0CIih2Q1GMxslZm9YGZbzezmDMsXmNlDZvaMmW0ws0uyWc9QushNRGS4rAWDmeUBtwEXA0uAa81syZDV/g64z91XAtcA38pWPZlUlWggPRGRobJ5xHAGsNXdX3H3buBe4LIh6zhQGk6XATuzWM8wh44YdGaSiMiA/CxuuxbYnvK8HjhzyDq3AL8xs/8OJIGLsljPMBpIT0RkuFx3Pl8L/Ju7zwMuAf7dzIbVZGarzWydma1raGiYtDcvLYyTFzP1MYiIpMhmMOwA5qc8nxfOS/WXwH0A7v4YUAjMHLohd7/D3evcva66unrSCozFjIpiDYshIpIqm8HwJHCimS0yswRB5/KaIeu8DlwIYGaLCYJh8g4JxqFKA+mJiKTJWjC4ey/wceBBYAvB2UebzOxLZnZpuNqngBvN7FngHuB6d/ds1ZSJBtITEUmXzc5n3H0tsHbIvC+kTG8GzslmDWOpLEmweWdrLksQEZlWct35nHNVyQSNbTpdVURkQOSDoTKZoLWrl56+/lyXIiIyLUQ+GAauZWhSP4OICKBgGBxIT2cmiYgEFAwaSE9EJE3kg0ED6YmIpIt8MAweMejMJBERQMFARXECMzUliYgMiHww5MWM8qK4mpJEREKRDwbQsBgiIqkUDEBVskBHDCIiIQUDOmIQEUmlYCAYSE/BICISUDAQDIvR1NFNX/+UjvgtIjItKRgImpLcoblDRw0iIgoGNCyGiEgqBQPBWUmgYTFEREDBAOiIQUQklYIBDaQnIpJKwUAwXhLA/jYFg4iIggFI5MeYUZjP/naNsCoiomAIVSUTakoSEUHBMEjDYoiIBMYVDGb2CTMrtcB3zexpM3t7toubSpXJAgWDiAjjP2L4r+7eCrwdqAA+AHwta1XlgJqSREQC4w0GCx8vAf7d3TelzBv5RWarzOwFM9tqZjePsM5VZrbZzDaZ2Q/HWc+kqyxJ0NTejbvGSxKRaMsf53pPmdlvgEXAZ81sBtA/2gvMLA+4DXgbUA88aWZr3H1zyjonAp8FznH3JjObdTg7MRmqkgl6+53Wzl7KiuO5KkNEJOfGGwx/CawAXnH3DjOrBG4Y4zVnAFvd/RUAM7sXuAzYnLLOjcBt7t4E4O57J1D7pBq8+rmjW8EgIpE23qaks4EX3L3ZzK4D/g5oGeM1tcD2lOf14bxUJwEnmdkfzexxM1uVaUNmttrM1pnZuoaGhnGWPDGHhsXQtQwiEm3jDYZvAx1mdirwKeBl4O5JeP984ETgAuBa4E4zKx+6krvf4e517l5XXV09CW873OBAerr6WUQibrzB0OtBr+xlwL+4+23AjDFeswOYn/J8XjgvVT2wxt173P1V4EWCoJhylSUaSE9EBMYfDAfM7LMEp6n+0sxiwFgN8U8CJ5rZIjNLANcAa4as8zOCowXMbCZB09Ir46xpUlUlNZCeiAiMPxiuBg4SXM+wm+Cv/6+P9gJ37wU+DjwIbAHuc/dNZvYlM7s0XO1BoNHMNgMPAZ9x98bD2I8jVhjPoziRpyMGEYm8cZ2V5O67zewHwJvM7F3An919zD4Gd18LrB0y7wsp0w78dfiTcxoWQ0Rk/ENiXAX8GbgSuAp4wsyuyGZhuaCrn0VExn8dw98Cbxq4zsDMqoHfAvdnq7BcqEwmaGjT6aoiEm3j7WOIDbn4rHECrz1qVCYLdLMeEYm88R4x/NrMHgTuCZ9fzZC+g2NBVUnQlOTumI05FJSIyDFpvJ3PnzGz9wHnhLPucPcHsldWblQmExzs7aeju49kwXgzU0Tk2DLubz93/wnwkyzWknOHhsXoVjCISGSN+u1nZgeATONQG8HZpqVZqSpHUi9ym19ZnONqRERyY9RgcPexhr04pmggPRGRY/DMoiOhgfRERBQMaTSQnoiIgiFNMpFHIj+mYBCRSFMwpDAzDYshIpGnYBhCA+mJSNQpGIao1BGDiEScgmGIqmRCp6uKSKRFJxgO7IENP4be0Y8GNJCeiERddILhtT/CTz8MezePulpVSYL27j66evqmqDARkeklOsEwd0XwuGv9qKuljpckIhJF0QmGikVQUAY714+6moJBRKIuOsFgBjXLxzxiSB1IT0QkiqITDBA0J+3ZNGoHtAbSE5Goi1Yw1KyAvm5o2DLiKhpIT0SiLlrBMHdl8Ljr2RFXKS3KJz9m6mMQkciKVjBULIKC0lE7oM2MCg2LISIRltVgMLNVZvaCmW01s5tHWe99ZuZmVpfNeojFoObUcXVAq/NZRKIqa8FgZnnAbcDFwBLgWjNbkmG9GcAngCeyVUuamlNh90bo6xlxFQ2kJyJRls0jhjOAre7+irt3A/cCl2VY738A/wB0ZbGWQ2pWQN9BaHh+xFUUDCISZdkMhlpge8rz+nDeIDM7DZjv7r8cbUNmttrM1pnZuoaGhiOrauAK6FH6GaqSCRrbdLqqiERTzjqfzSwGfBP41Fjruvsd7l7n7nXV1dVH9saVJ0Bixqj9DJXJAlq7eunp6z+y9xIROQplMxh2APNTns8L5w2YASwDHjazbcBZwJqp6YBePuopqwP3fm5Sc5KIRFA2g+FJ4EQzW2RmCeAaYM3AQndvcfeZ7r7Q3RcCjwOXuvu6LNYUqFkRdkD3ZlysYTFEJMqyFgzu3gt8HHgQ2ALc5+6bzOxLZnZptt53XOaugN5O2PdCxsUaSE9Eoiw/mxt397XA2iHzvjDCuhdks5Y0NSuCx53rYfbSYYt1xCAiURatK58HVJ0A8eSIHdCDRww6M0lEIiiawRDLCzqgRzhltbw4gZmakkQkmqIZDBB2QD+XsQM6L2ZUFGtYDBGJpugGw2AH9IsZF+vqZxGJqugGw0AH9AjXM1RqID0RiajoBsPME0ftgK7SEYOIRFR0gyGWB3NOGbEDWk1JIhJV0Q0GCPoZdm+A/r5hi6qSCZo6uunr96mvS0Qkh6IdDDWnQk8H7Htp2KLKZAJ3aO7QUYOIREvEg2FF8Jihn6GypADQtQwiEj3RDoaZJ0F+UcZ+Bg2LISJRFe1gyMsPOqAznLKqgfREJKqiHQyQ0gGdflMeHTGISFQpGGpWQHcbNG5Nm10xOJCegkFEokXBMHAP6CEd0PG8GKWF+exv1wirIhItCoaZb4T8wswd0CUFakoSkchRMOTlw+xlmU9Z1dXPIhJBCgYImpN2De+Arkwm2NPalZuaRERyRMEAYQf0Adj/ctrsMxdV8nJDO89ub85JWSIiuaBggJQO6PTrGa45YwEzCvO545FXpr4mEZEcUTAAVJ8MeQWw85m02SUF+Vx31nH8auMutu1rz1FxIiJTS8EAkBeHOcsyXgF9w5sXkh+L8a+P6qhBRKJBwTCgZkUQDEM6oGeVFnL5ylp+vK6exjZd0yAixz4Fw4C5K+BgKzS9OmzRjecdz8Hefr7/2GtTX5eIyBTLajCY2Soze8HMtprZzRmW/7WZbTazDWb2OzM7Lpv1jKrm1OBxSD8DwBtmlfC2JbO5+7FtdHT3TnFhIiJTK2vBYGZ5wG3AxcAS4FozWzJktWeAOndfDtwP/GO26hlT9WLIS4x4D+iPnHc8zR09/Hhd/dTWJSIyxbJ5xHAGsNXdX3H3buBe4LLUFdz9IXfvCJ8+DszLYj2jy0/A7KUZO6AB6hZWcvpxFdz5h1fo7evPuI6IyLEgm8FQC2xPeV4fzhvJXwK/ymI9YxvogPbM93n+yHnHU9/UydqNu6e2LhGRKTQtOp/N7DqgDvj6CMtXm9k6M1vX0NCQvULmroCulowd0AAXLZ7N8dVJ7njkZXyE8BAROdplMxh2APNTns8L56Uxs4uAvwUudfeM54O6+x3uXufuddXV1VkpFjh0D+gMI60CxGLG6nOPZ+OOVv70cmP26hARyaFsBsOTwIlmtsjMEsA1wJrUFcxsJXA7QSjszWIt4zNrCcTiI3ZAA7xnZS3VMwq4XcNkiMgxKmvB4O69wMeBB4EtwH3uvsnMvmRml4arfR0oAX5sZuvNbM0Im5sa+QmYvWTEIwaAwnge1795IY+82MDmna1TV5uIyBTJah+Du69195Pc/QR3/0o47wvuviacvsjdZ7v7ivDn0tG3OAXG6IAGuO7M40gm8rjjkZdHXEdE5Gg1LTqfp5W5K6CrGZq2jbhKWXGca89YwC827KK+qWPE9UREjkYKhqEGOqBHuJ5hwH99yyIMuOvRbdmuSERkSikYhpq9dMwOaIC55UVceupc7n3ydVo6eqamNhGRKaBgGCq/AGYtHrUDesDq84+no7uP//uEBtcTkWOHgiGTuSuCI4YxLmI7eU4p559Uzff++CpdPX1TUpqISLYpGDKpWQGdTdD8+pirfuT849nX1s1Pnx527Z6IyFFJwZDJYAf0+jFXPfv4Kk6pLeNf//AKff0aJkNEjn4KhkxmL4VY/rj6GcyMj5x/PK/sa+c/Nu/Jfm0iIlmmYMgkXhjcn2GMU1YHrFo6hwWVxdyuwfVE5BigYBjJ3FPH1QENkJ8X48PnLuKZ15tZ91pT9msTEckiBcNIalZARyO0jO+ObVeePp+K4ji3/17DZIjI0U3BMJK5K4PHcXRAAxQl8vjQmxfy2y17eWH3gezVJSKSZQqGkcxeCpY3rg7oAR88eyHJRB6X/sujfObHz/JcfUv26hMRyZL8XBcwbcWLgiugtz8B/f0QGztDK5MJfv7xc/juo9v42TM7+PFT9ayYX84Hzz6Ody6voSA/bwoKFxE5MjpiGM1J74Btf4Dvvg12PjOul7xh1gy++t5TePxzF/KFdy2htbOHv77vWc7+6n/yD79+/qgZjbWnr5/HXm6kuaM716WIyBSzo+30yrq6Ol+3bt3UvJk7bPgR/Obz0N4AdTfAX3weiivHvYn+fuePL+/j7sde43dbgusc/uLk2Xzw7ON4yxtmEotZtqo/bI++tI9bfrGJrXvbyIsZZx9fxTuWzeEdS2Yzq7Qw1+WJyGEws6fcvW5c6yoYxqGrBR76Kvz5digsh4tugZUfGFfzUqr6pg5++MTr/OjJ7TS2d7NoZpLrzjqOK06fR1lRPCulT8SO5k6+8svNrH1uNwsqi7npwhN5paGNX2/czSv72jGD0xZUsGrpHN6xdA4LqopzXbKIjJOCIVt2b4S1n4bXH4PaOnjnNw6dvTQBB3v7WPvcLu5+7DWeeb2ZRH6M5bVlnDq/nFPnl7NyfjnzKoowm5qjia6ePu585BVue3grAB+74A3ceN7xFMaDPhF3Z+veICB+vWk3m8Jbmi6uKWXV0jmsWjaHk2aXTFm9IjJxCoZsmoTmpVQbd7Tws2d28Mz2ZjbuaOFgbz8AVclEEBTzylmxoJxT55VRXpyYzD0B4Hdb9vD3v9jM6/s7uOSUOfztO5dQW1406mu27+/gwU27+fXG3Tz1ehPusGhmkncsncNFi2exrLZsMFREZHpQMEyFwealO6Cw7LCbl1L19PXzwu4DrN/ezLPbm1m/vZmtDW2DF18vrCpmRXhUcer8chbPKaUocXhfwK/ua+dLv9jEQy80cEJ1kr+/dBlvOXHmhLezt7WL32zew4ObdvPYy4309jvxPGNJTSkr5pezckEFKxeUs6CyWEcUIjmkYJhKac1Lp8Ml34Da0yZt8we6enhuR0taWOxpPQhAzOCE6hKW1ZaxdG4pS+eWsWRu6aj9FR3dvdz20FbufORVEvkxPnHhiXzozQtJ5B/5CWrNHd088ep+1m9v5pnXm9hQ30JHd3CfispkghXzy8OwCIKttDB7/SruTmtXL3tbu9jTepCO7l6qShJUJQuoLEkwoyD/mAiqvn7nQFcPLZ3Df1o7e2np7KH9YC+1FUUsrillSU0p1TMKcl225ICCYaq5w4b74Dd/FzQvvfFiWH41nLQqGJBvku1q6eS5+hY27Wxl084WNu5oZXdr1+DyBZXFLKsNgmIgNKqSCdY+t5sv/3Izu1q6eO/KWm6++OSsnmXU29fPS3vbeOb1ZtZvb+KZ19OPgN4wq4QV88upLS+iKJFHYX6MwngeRYk8CvLzhs0rzM+jMBEjHovR2N7N3gNd7G09yJ7wy3/PgS72tnax90Awr6unf8TaEnmxICjCsKgqSTCzpIDKZIKqZDBdVhyntDCfGYVxZhTmUxTPm7Iw6e3rZ8+Bg+xs7mRHUyc7mjupDx8b2w4Ofvkf6OoddTvxPKM4kU9L56Hbz84sKWBxzQyW1JSyZG4pi2tKOX5mkvy8Y+fs9T2tXTzzejPPbG+itbOHymSCymQBVcngMw8+5+Dznow/io4GCoZc6WqBR2+F9T+Ett1QUAZLLwtCYsGbj6iZaSwNBw6yaWd6WLy+/9A1E2VFcVo6e1hSU8qXLltK3cLD6xM5Uq1dPWzY3sIzrzexPjwCamw/8mslihN5zC4tZNaMAmaXFjK7NHisDp8nE/ns7+imse0gjW3d7GsPHve3B/P2tXWzr+3gYB9PJnkxo6QgnxkpYVFamB/OC54n8mPE82LE84x4Xoz8vBiJPCM/FiOeHyMeC+YPTPf0OzubOwcDoD583N3aNez+HlXJBLUVRVSXFFBWFKe0KJ72mOmnMB7DzGju6Gbzrla27DrAll2tbNnVykt72ujuC/Y3kR/jpNklLKkJguKNs2dQW1HEnLLCaX9hZldPHxt3tIR/gARHqztbgj+U4nlGWVGCpo7uEe+XMqMwn6pkGBYlQXiUFyeoKI5TXhynvDhBeVGcimTwWFYcH/N34u509fTT1NFNU0c3LR09NHX00NzZTXNHD03t3Rzs7Q//LRjxWCz892Ikwn8/wb+dYN7Av6kTqks4cfaMw/o9KRhyrb8PXv19cBSxeQ30tEPpPFh+JSy/BmadPCVltHT2sDkMii27DrByQTnXnrGAvGl27UR/v3Owt5/Onj66evoGH7t6+sPHYHpgfndvP5XJBLPCL/9ZMwoomYSmIXeno7tvMDgG/iI/0DX0ccj0wWC6rauX3sO8WVPMoKasiNryIuaWF1JbUURteXH4WDR4VDWZevr6ebmhLQyKA2zeGQTG0KCeWZKgpqyImrJC5ob11ZQdepw1o2DKjjbcnW2NHYN/WDzzejNbdrUO/t7nVRSxckHFYJPlkppSCuN59Pc7rV09NLZ3h38QHKSxvZv9bd3BvPZwXvi8uaObnr6RP8viRB7lRWFoFMdJFuTT2tlDc/jl39TRQ/cof2QUxfMojMfo7XO6+/rp6etnPP90/ur8E7j54sP7/lAwTCfd7fDCr4Izmbb+DrwP5iwPjiJOuQJmzMl1hTKJ+vudnv5+evqc3r5+uvv66e1zevqCeT3h84Evg7yYUVNWyJzSwmnRlOPuNBw4yEt729jZ3Mmuli52tXSyszl43NXcxYGD6c1XMYPZpYWUFsZxPNxOuL2U7Q4+z7Ds0DTDt5HyFXWgq4fWsPksmcgLTu9eUM6K+UEYTFb/ycAfCU0dwV/4qV/4LeG8po4eWsJ57Qd7KS0cOMKIU1GcGAyNiuI4ZUUJKpLB/OBIbnjI9/WH/z76nZ7e4N9HTzjd299Pd69TmUwwp+zwmn+nTTCY2SrgfwN5wL+6+9eGLC8A7gZOBxqBq91922jbPOqCIVXbXtj40yAkdj4NFoNF58PS90BRZfA8lhcM3mexoOlpcDqcH8sDM4gnoWQWFFUEzyeTe3DP686m4IK+ooqsNoPJ0aW1q4ddzV3sDINiIDjaDvZg2OA/x8FHBicGHwaO7gb+5ZqlTqcsS9mGGRTGYyybW8bKBRW8YVbJtDv6nc6mRTCYWR7wIvA2oB54ErjW3TenrPPfgOXu/ldmdg1wubtfPdp2j+pgSLXvpaCpacOPoPm1w99OXgJKZgc/M+akTM+Gkjnh42xIzoK+bmjbEwRU254M0wPP90L/oc5KYvnB60uqw+3POrTNgemScLqgdPKDSkSO2HQJhrOBW9z9HeHzzwK4+1dT1nkwXOcxM8sHdgPVPkpRx0wwDHCHxq3Q2wXeH/RPeH/KdF/6dH+4rLst/BLfDQf2BI9te+HAbujcP/73txgkq1O+4FO++IsqoLP5UGC0700PD+/LtMHwqCblaGfwJ3VZ7NA6I/9yxio+fLCU6QzzB4NqSGANC7Cxlh+mrDfXDtn+sPcba3mGddJk+B2O9TxrhrYvjfV8iKztR6b3TZkeWt/wwkZ+/9R5p30Q3vzxCdY2sJnxB0M2h92uBbanPK8HzhxpHXfvNbMWoArYl7qSma0GVgMsWLAgW/XmhhnMPHFyt9mbemSwOwiLtr2QXzD8yz85M/iynqj+/qCpaeBIo70heOxsPhRsgz9+KOBSfwZCcLT/hCMt8pSJ1P90w6ZH+qKY4JfpeLiPEiaT9YXpmbc14ZAbzzYY4Xc4wS/jEY2wL2M57C/3bO3HCHWlzctU38Dbjvb+Q+aVzDq82iboqLgfg7vfAdwBwRFDjsuZ/vITUD4/+MmWWAySVcHP7CXZex8RmXLZ7FHcAaR+M80L52VcJ2xKKiPohBYRkRzJZjA8CZxoZovMLAFcA6wZss4a4EPh9BXAf47WvyAiItmXtaaksM/g48CDBKer3uXum8zsS8A6d18DfBf4dzPbCuwnCA8REcmhrPYxuPtaYO2QeV9Ime4CrsxmDSIiMjG6aklERNIoGEREJI2CQURE0igYREQkzVE3uqqZNQCHO7jQTIZcVR0xUd7/KO87RHv/te+B49y9ejwvOuqC4UiY2brxjhVyLIry/kd53yHa+699n/i+qylJRETSKBhERCRN1ILhjlwXkGNR3v8o7ztEe/+17xMUqT4GEREZW9SOGEREZAwKBhERSROZYDCzVWb2gpltNbObc13PVDKzbWb2nJmtN7Nj6L6omZnZXWa218w2psyrNLP/MLOXwseKXNaYLSPs+y1mtiP8/Neb2SW5rDFbzGy+mT1kZpvNbJOZfSKcH5XPfqT9n/DnH4k+BjPLA14E3kZwi9EngWvdfXNOC5siZrYNqHP3SFzkY2bnAW3A3e6+LJz3j8B+d/9a+IdBhbv/TS7rzIYR9v0WoM3dv5HL2rLNzGqAGnd/2sxmAE8B7wGuJxqf/Uj7fxUT/PyjcsRwBrDV3V9x927gXuCyHNckWeLujxDc3yPVZcD3w+nvE/yHOeaMsO+R4O673P3pcPoAsIXgvvJR+exH2v8Ji0ow1ALbU57Xc5i/sKOUA78xs6fMbHWui8mR2e6+K5zeDczOZTE58HEz2xA2NR2TTSmpzGwhsBJ4ggh+9kP2Hyb4+UclGKLuLe5+GnAx8LGwuSGywtvHHvttqId8GzgBWAHsAv5XTqvJMjMrAX4CfNLdW1OXReGzz7D/E/78oxIMO4D5Kc/nhfMiwd13hI97gQcImtaiZk/YBjvQFrs3x/VMGXff4+597t4P3Mkx/PmbWZzgS/EH7v7TcHZkPvtM+384n39UguFJ4EQzW2RmCYJ7S6/JcU1TwsySYUcUZpYE3g5sHP1Vx6Q1wIfC6Q8BP89hLVNq4EsxdDnH6OdvZkZwH/kt7v7NlEWR+OxH2v/D+fwjcVYSQHiK1q1AHnCXu38ltxVNDTM7nuAoAYJ7fP/wWN93M7sHuIBgyOE9wBeBnwH3AQsIhm2/yt2PuU7aEfb9AoJmBAe2AR9JaXM/ZpjZW4A/AM8B/eHszxG0s0fhsx9p/69lgp9/ZIJBRETGJypNSSIiMk4KBhERSaNgEBGRNAoGERFJo2AQEZE0CgaRKWRmF5jZ/8t1HSKjUTCIiEgaBYNIBmZ2nZn9ORy//nYzyzOzNjP7p3Cs+9+ZWXW47gozezwcpOyBgUHKzOwNZvZbM3vWzJ42sxPCzZeY2f1m9ryZ/SC8YlVk2lAwiAxhZouBq4Fz3H0F0Ae8H0gC69x9KfB7gquKAe4G/sbdlxNcdTow/wfAbe5+KvBmggHMIBj18pPAEuB44Jws75LIhOTnugCRaehC4HTgyfCP+SKCgdf6gR+F6/xf4KdmVgaUu/vvw/nfB34cjk9V6+4PALh7F0C4vT+7e334fD2wEHg063slMk4KBpHhDPi+u382babZ54esd7jjyRxMme5D/w9lmlFTkshwvwOuMLNZMHjP4OMI/r9cEa7zX4BH3b0FaDKzc8P5HwB+H95Bq97M3hNuo8DMiqdyJ0QOl/5SERnC3Teb2d8R3PUuBvQAHwPagTPCZXsJ+iEgGMr5O+EX/yvADeH8DwC3m9mXwm1cOYW7IXLYNLqqyDiZWZu7l+S6DpFsU1OSiIik0RGDiIik0RGDiIikUTCIiEgaBYOIiKRRMIiISBoFg4iIpPn/mOm+Cth40nsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "#  \"Accuracy\"\n",
    "plt.plot(version1.history['accuracy'])\n",
    "plt.plot(version1.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(version1.history['loss'])\n",
    "plt.plot(version1.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation']) #loc='lower right'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 2s 8ms/step - loss: 1.7507e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7507190932519734e-06, 1.0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9941264986991882"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = version1.history['accuracy']\n",
    "np.amax(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   downwards       1.00      1.00      1.00       221\n",
      "       front       1.00      1.00      1.00       467\n",
      "        side       1.00      1.00      1.00       892\n",
      "     upwards       1.00      1.00      1.00        80\n",
      "\n",
      "    accuracy                           1.00      1660\n",
      "   macro avg       1.00      1.00      1.00      1660\n",
      "weighted avg       1.00      1.00      1.00      1660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "y_test_numeric = y_test.rename(columns={\"downwards\": 0, \"front\": 1, \"side\": 2, \"upwards\": 3})\n",
    "predictions = model.predict(x=X_test, batch_size=128)\n",
    "print(classification_report(y_test_numeric.idxmax(axis=\"columns\").values,\n",
    "                            predictions.argmax(axis=1), target_names=['downwards', 'front', 'side', 'upwards']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating our Video Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model architecture and loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "from glob import glob\n",
    "from scipy import stats as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base pretrained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(153600,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the trained weights\n",
    "model.load_weights(\"weight_v1.hdf5\")\n",
    "\n",
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating predictions for all test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in test labels for verification later\n",
    "train = pd.read_csv('material/test_labels.csv', sep=';')\n",
    "\n",
    "# creating the dummy tags\n",
    "trainLabel = pd.read_csv('material/train_frames.csv')\n",
    "y = trainLabel['class']\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:23<00:00,  3.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# creating two lists to store predicted and actual tags\n",
    "predict = []\n",
    "actual = []\n",
    "\n",
    "# for loop to extract frames from each test video\n",
    "for i in tqdm(range(train['NameOfFile'].shape[0])):\n",
    "    count = 0\n",
    "    videoFile = train['NameOfFile'][i]\n",
    "    cap = cv2.VideoCapture('material/raw_test_videos/'+videoFile)   # capturing the video from the given path\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    \n",
    "    # removing all other files from the temp folder\n",
    "    files = glob('temp/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1) #current frame number\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        #if (frameId % math.floor(frameRate) == 0):\n",
    "            # storing the frames of this particular video in temp folder\n",
    "        else:\n",
    "            filename ='temp/' + \"_frame%d.jpg\" % count;count+=1\n",
    "            cv2.imwrite(filename, frame)\n",
    "    cap.release()\n",
    "    \n",
    "    # reading all the frames from temp folder\n",
    "    images = glob(\"temp/*.jpg\")\n",
    "    \n",
    "    prediction_images = []\n",
    "    for i in range(len(images)):\n",
    "        img = image.load_img(images[i], target_size=(480, 640, 3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img/480\n",
    "        prediction_images.append(img)\n",
    "    \n",
    "    # converting all the frames for a test video into numpy array\n",
    "    prediction_images = np.array(prediction_images)\n",
    "    \n",
    "    # extracting features using pre-trained model\n",
    "    prediction_images = base_model.predict(prediction_images)\n",
    "    \n",
    "    # converting features in one dimensional array\n",
    "    prediction_images = prediction_images.reshape(prediction_images.shape[0], 15*20*512)\n",
    "    \n",
    "    # predicting tags for each array\n",
    "    # predicting tags for each array\n",
    "    prediction = (model.predict(prediction_images) > 0.5).astype(\"int32\")\n",
    "    predictFrame = []\n",
    "    for pre in prediction:\n",
    "        if pre[0] == 1:\n",
    "            predictFrame.append('downwards')\n",
    "        elif pre[1] == 1:\n",
    "            predictFrame.append('front')\n",
    "        elif pre[2] == 1:\n",
    "            predictFrame.append('side')\n",
    "        else:\n",
    "            predictFrame.append('upwards')\n",
    "\n",
    "    # appending the mode of predictions in predict list to assign the tag to the video\n",
    "    predict.append(s.mode(predictFrame)[0][0])\n",
    "    \n",
    "    # appending the actual tag of the video\n",
    "    actual.append(train['label'].loc[train['NameOfFile'] == videoFile].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the accuracy of the predicted tags\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model by looking at Frame prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in test labels for verification later\n",
    "train = pd.read_csv('material/test_labels.csv', sep=';')\n",
    "\n",
    "# creating the dummy tags\n",
    "trainLabel = pd.read_csv('material/train_frames.csv')\n",
    "y = trainLabel['class']\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:11<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# create all frames and csv with labels and frame name\n",
    "\n",
    "# clear temp folder\n",
    "files = glob('temp/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "frameFileNames = []\n",
    "frameFileLabels = []\n",
    "\n",
    "# for loop to extract frames from each test video\n",
    "for i in tqdm(range(train['NameOfFile'].shape[0])):\n",
    "    count = 0\n",
    "    videoFile = train['NameOfFile'][i]\n",
    "    cap = cv2.VideoCapture('material/raw_test_videos/'+videoFile)   # capturing the video from the given path\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    x=1\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1) #current frame number\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        else:\n",
    "            filename ='temp/' + videoFile + \"_frame%d.jpg\" % count;count+=1\n",
    "            frameFileNames.append(filename)\n",
    "            frameFileLabels.append(train['label'][i])\n",
    "            cv2.imwrite(filename, frame)\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "# storing the images and their labels in a dataframe\n",
    "test_frames = pd.DataFrame()\n",
    "test_frames['image'] = frameFileNames\n",
    "test_frames['label'] = frameFileLabels\n",
    "\n",
    "# converting the dataframe into csv file \n",
    "test_frames.to_csv('temp/test_frames.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predicitons on all frames\n",
    "\n",
    "\n",
    "# creating two lists to store predicted and actual tags\n",
    "predictFrame = []\n",
    "actualFrame = []\n",
    "\n",
    "# reading all the frames from temp folder\n",
    "images = glob(\"temp/*.jpg\")\n",
    "\n",
    "# reading actual labels from temp folder\n",
    "train = pd.read_csv('temp/test_frames.csv')\n",
    "\n",
    "# open all frames and convert to np array\n",
    "prediction_images = []\n",
    "for i in range(len(images)):\n",
    "    img = image.load_img(images[i], target_size=(480, 640, 3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/480\n",
    "    prediction_images.append(img)\n",
    "    actualFrame.append(train['label'].loc[train['image'] == images[i]].values[0])\n",
    "\n",
    "# converting all the frames for a test video into numpy array\n",
    "prediction_images = np.array(prediction_images)\n",
    "\n",
    "# extracting features using pre-trained model\n",
    "prediction_images = base_model.predict(prediction_images)\n",
    "\n",
    "# converting features in one dimensional array\n",
    "prediction_images = prediction_images.reshape(prediction_images.shape[0], 15*20*512)\n",
    "\n",
    "# predicting tags for each array\n",
    "prediction = (model.predict(prediction_images) > 0.5).astype(\"int32\")\n",
    "for pre in prediction:\n",
    "    if pre[0] == 1:\n",
    "        predictFrame.append('downwards')\n",
    "    elif pre[1] == 1:\n",
    "        predictFrame.append('front')\n",
    "    elif pre[2] == 1:\n",
    "        predictFrame.append('side')\n",
    "    else:\n",
    "        predictFrame.append('upwards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "# checking predicted and actual frames labels which dont match\n",
    "count_corrcet = 0\n",
    "count_false = 0\n",
    "for i in range(0, len(predictFrame)):\n",
    "    if predictFrame[i] == actualFrame[i]:\n",
    "        count_corrcet +=1\n",
    "    else:\n",
    "        print('frame ' + str(i),predictFrame[i], actualFrame[i])\n",
    "        print(frameName[i])\n",
    "        count_false +=1\n",
    "\n",
    "test_acc = (count_corrcet / (count_corrcet + count_false)) *100\n",
    "print('Test Accuracy {:.2f}%'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate single Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear temp folder\n",
    "files = glob('temp/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "# extract frames from the video and store them\n",
    "count = 0\n",
    "# videoFile = '_tigfCJFLZg_00214.mp4' # should be \"downwards\" but is \"front\"\n",
    "# videoFile = '_8Vy3dlHg2w_00001.mp4' # should be \"upwards\" is \"upwards\"\n",
    "# videoFile = '3PLiUG_DuC8_00346.mp4' # should be \"upwards\" but is \"downwards\"\n",
    "videoFile = '_tigfCJFLZg_00181.mp4' # should be \"side\" is \"side\"\n",
    "#videoFile = 'Video_62.mp4' # should be \"front\" but includes camera switch\n",
    "cap = cv2.VideoCapture('material/single_videos/'+videoFile)   # capturing the video from the given path\n",
    "frameRate = cap.get(5) #frame rate\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    else:\n",
    "        filename ='temp/' + videoFile + \"_frame%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "\n",
    "# creating two lists to store predicted and actual tags\n",
    "predictFrame = []\n",
    "\n",
    "# reading all the frames from temp folder\n",
    "images = glob(\"temp/*.jpg\")\n",
    "\n",
    "# open all frames and convert to np array\n",
    "prediction_images = []\n",
    "for i in range(len(images)):\n",
    "    img = image.load_img(images[i], target_size=(480, 640, 3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/480\n",
    "    prediction_images.append(img)\n",
    "\n",
    "# converting all the frames for a test video into numpy array\n",
    "prediction_images = np.array(prediction_images)\n",
    "\n",
    "# extracting features using pre-trained model\n",
    "prediction_images = base_model.predict(prediction_images)\n",
    "\n",
    "# converting features in one dimensional array\n",
    "prediction_images = prediction_images.reshape(prediction_images.shape[0], 15*20*512)\n",
    "\n",
    "# predicting tags for each array\n",
    "prediction = (model.predict(prediction_images) > 0.5).astype(\"int32\")\n",
    "for pre in prediction:\n",
    "    if pre[0] == 1:\n",
    "        predictFrame.append('downwards')\n",
    "    elif pre[1] == 1:\n",
    "        predictFrame.append('front')\n",
    "    elif pre[2] == 1:\n",
    "        predictFrame.append('side')\n",
    "    else:\n",
    "        predictFrame.append('upwards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'front',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'front',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'front',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'front',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'front',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'front',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side',\n",
       " 'side']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'side'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#most labels say:\n",
    "s.mode(predictFrame)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  0 false:  133\n"
     ]
    }
   ],
   "source": [
    "# checking predicted and actual frames labels which dont match\n",
    "counterA = 0\n",
    "counterB = 0\n",
    "for i in range(0, len(predictFrame)):\n",
    "    if predictFrame[i] == 'downwards':\n",
    "        counterA +=1\n",
    "    else:\n",
    "        counterB +=1 \n",
    "print('correct: ', counterA, 'false: ',counterB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
