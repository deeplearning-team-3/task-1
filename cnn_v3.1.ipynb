{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Notebook basiert auf diesem Turoial:\n",
    "# https://www.analyticsvidhya.com/blog/2019/09/step-by-step-deep-learning-tutorial-video-classification-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv with labels for frames\n",
    "train = pd.read_csv('material/train_frames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8300/8300 [02:33<00:00, 54.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8300, 480, 640, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in all the frames and saving them to a numpy array\n",
    "\n",
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the image size (480, 640, 3)\n",
    "    '''\n",
    "    TO DO:\n",
    "    finde heraus was die ideale input größe der Bilder ist. \n",
    "    '''\n",
    "    img = image.load_img('material/train_frames/'+train['image'][i], target_size=(480, 640, 3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    '''\n",
    "    TO DO:\n",
    "    finde heraus was die optimale normalisierung der Bild daten ist\n",
    "    '''\n",
    "    img = img/480\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)\n",
    "    \n",
    "# converting the list to numpy array\n",
    "X = np.array(train_image)\n",
    "\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and test set\n",
    "\n",
    "# separating the target\n",
    "y = train['class']\n",
    "\n",
    "# creating the training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummies of target variable for train and validation set\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the architecture of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model without transferlearning based on:\n",
    "# https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/\n",
    "init=\"he_normal\"\n",
    "inputShape = (480, 640, 3)\n",
    "reg = l2(0.0005)\n",
    "chanDim = -1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (7, 7), strides=(2, 2), padding=\"valid\",\n",
    "                 kernel_initializer=init, kernel_regularizer=reg,input_shape=inputShape))\n",
    "\n",
    "\n",
    "# fully-connected layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# softmax classifier\n",
    "model.add(Dense(4))\n",
    "model.add(Activation(\"softmax\"))\n",
    "# return the constructed network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 237, 317, 16)      2368      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1202064)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 4808260   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 4,810,628\n",
      "Trainable params: 4,810,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('weight_v3.1.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model wird hier trainiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "52/52 [==============================] - 21s 397ms/step - loss: 26.3501 - accuracy: 0.7685 - val_loss: 3.5522 - val_accuracy: 0.8446\n",
      "Epoch 2/25\n",
      "52/52 [==============================] - 16s 317ms/step - loss: 0.9959 - accuracy: 0.9401 - val_loss: 0.4193 - val_accuracy: 0.9645\n",
      "Epoch 3/25\n",
      "52/52 [==============================] - 16s 309ms/step - loss: 0.1657 - accuracy: 0.9767 - val_loss: 0.1370 - val_accuracy: 0.9873\n",
      "Epoch 4/25\n",
      "52/52 [==============================] - 16s 314ms/step - loss: 0.0409 - accuracy: 0.9923 - val_loss: 0.0759 - val_accuracy: 0.9819\n",
      "Epoch 5/25\n",
      "52/52 [==============================] - 17s 336ms/step - loss: 0.0222 - accuracy: 0.9982 - val_loss: 0.0401 - val_accuracy: 0.9928\n",
      "Epoch 6/25\n",
      "52/52 [==============================] - 11s 208ms/step - loss: 0.0204 - accuracy: 0.9992 - val_loss: 0.0401 - val_accuracy: 0.9946\n",
      "Epoch 7/25\n",
      "52/52 [==============================] - 12s 224ms/step - loss: 0.0182 - accuracy: 0.9994 - val_loss: 0.0323 - val_accuracy: 0.9958\n",
      "Epoch 8/25\n",
      "52/52 [==============================] - 12s 223ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9952\n",
      "Epoch 9/25\n",
      "52/52 [==============================] - 11s 214ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9946\n",
      "Epoch 10/25\n",
      "52/52 [==============================] - 15s 294ms/step - loss: 0.0182 - accuracy: 0.9989 - val_loss: 0.0367 - val_accuracy: 0.9952\n",
      "Epoch 11/25\n",
      "52/52 [==============================] - 13s 252ms/step - loss: 0.0208 - accuracy: 0.9988 - val_loss: 0.0443 - val_accuracy: 0.9946\n",
      "Epoch 12/25\n",
      "52/52 [==============================] - 12s 239ms/step - loss: 0.0190 - accuracy: 0.9988 - val_loss: 0.0482 - val_accuracy: 0.9928\n",
      "Epoch 13/25\n",
      "52/52 [==============================] - 10s 198ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 0.9958\n",
      "Epoch 14/25\n",
      "52/52 [==============================] - 10s 200ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9958\n",
      "Epoch 15/25\n",
      "52/52 [==============================] - 10s 187ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9946\n",
      "Epoch 16/25\n",
      "52/52 [==============================] - 10s 188ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9952\n",
      "Epoch 17/25\n",
      "52/52 [==============================] - 11s 209ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9952\n",
      "Epoch 18/25\n",
      "52/52 [==============================] - 12s 223ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9952\n",
      "Epoch 19/25\n",
      "52/52 [==============================] - 12s 221ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9952\n",
      "Epoch 20/25\n",
      "52/52 [==============================] - 13s 245ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9952\n",
      "Epoch 21/25\n",
      "52/52 [==============================] - 11s 213ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9952\n",
      "Epoch 22/25\n",
      "52/52 [==============================] - 10s 196ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9952\n",
      "Epoch 23/25\n",
      "52/52 [==============================] - 10s 187ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9952\n",
      "Epoch 24/25\n",
      "52/52 [==============================] - 10s 196ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 0.9952\n",
      "Epoch 25/25\n",
      "52/52 [==============================] - 10s 183ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9952\n",
      "CPU times: user 12min 59s, sys: 8min 1s, total: 21min 1s\n",
      "Wall time: 5min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training the model \n",
    "\n",
    "version31 = model.fit(X_train, y_train, epochs=25, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "#  \"Accuracy\"\n",
    "plt.plot(version31.history['accuracy'])\n",
    "plt.plot(version31.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(version31.history['loss'])\n",
    "plt.plot(version31.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation']) #loc='lower right'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 7s 33ms/step - loss: 0.0156 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.015635622665286064, 1.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = version31.history['accuracy']\n",
    "np.amax(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   downwards       1.00      1.00      1.00       221\n",
      "       front       1.00      0.99      1.00       467\n",
      "        side       0.99      1.00      1.00       892\n",
      "     upwards       0.97      0.97      0.97        80\n",
      "\n",
      "    accuracy                           1.00      1660\n",
      "   macro avg       0.99      0.99      0.99      1660\n",
      "weighted avg       1.00      1.00      1.00      1660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "y_test_numeric = y_test.rename(columns={\"downwards\": 0, \"front\": 1, \"side\": 2, \"upwards\": 3})\n",
    "predictions = model.predict(x=X_test, batch_size=128)\n",
    "print(classification_report(y_test_numeric.idxmax(axis=\"columns\").values,\n",
    "                            predictions.argmax(axis=1), target_names=['downwards', 'front', 'side', 'upwards']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating our Video Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model architecture and loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "from glob import glob\n",
    "from scipy import stats as s\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model without transferlearning based on:\n",
    "# https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/\n",
    "init=\"he_normal\"\n",
    "inputShape = (480, 640, 3)\n",
    "reg = l2(0.0005)\n",
    "chanDim = -1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (7, 7), strides=(2, 2), padding=\"valid\",\n",
    "                 kernel_initializer=init, kernel_regularizer=reg,input_shape=inputShape))\n",
    "\n",
    "\n",
    "# fully-connected layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# softmax classifier\n",
    "model.add(Dense(4))\n",
    "model.add(Activation(\"softmax\"))\n",
    "# return the constructed network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the trained weights\n",
    "model.load_weights(\"weight_v3.1.hdf5\")\n",
    "\n",
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating predictions for all test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in test labels for verification later\n",
    "train = pd.read_csv('material/test_labels.csv', sep=';')\n",
    "\n",
    "# creating the dummy tags\n",
    "trainLabel = pd.read_csv('material/train_frames.csv')\n",
    "y = trainLabel['class']\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:30<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# creating two lists to store predicted and actual tags\n",
    "predict = []\n",
    "actual = []\n",
    "\n",
    "# for loop to extract frames from each test video\n",
    "for i in tqdm(range(train['NameOfFile'].shape[0])):\n",
    "    count = 0\n",
    "    videoFile = train['NameOfFile'][i]\n",
    "    cap = cv2.VideoCapture('material/raw_test_videos/'+videoFile)   # capturing the video from the given path\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    \n",
    "    # removing all other files from the temp folder\n",
    "    files = glob('temp/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1) #current frame number\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        #if (frameId % math.floor(frameRate) == 0):\n",
    "            # storing the frames of this particular video in temp folder\n",
    "        else:\n",
    "            filename ='temp/' + \"_frame%d.jpg\" % count;count+=1\n",
    "            cv2.imwrite(filename, frame)\n",
    "    cap.release()\n",
    "    \n",
    "    # reading all the frames from temp folder\n",
    "    images = glob(\"temp/*.jpg\")\n",
    "    \n",
    "    prediction_images = []\n",
    "    for i in range(len(images)):\n",
    "        img = image.load_img(images[i], target_size=(480, 640, 3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img/480\n",
    "        prediction_images.append(img)\n",
    "    \n",
    "    # converting all the frames for a test video into numpy array\n",
    "    prediction_images = np.array(prediction_images)\n",
    "\n",
    "    # predicting tags for each array\n",
    "    # predicting tags for each array\n",
    "    prediction = (model.predict(prediction_images) > 0.5).astype(\"int32\")\n",
    "    predictFrame = []\n",
    "    for pre in prediction:\n",
    "        if pre[0] == 1:\n",
    "            predictFrame.append('downwards')\n",
    "        elif pre[1] == 1:\n",
    "            predictFrame.append('front')\n",
    "        elif pre[2] == 1:\n",
    "            predictFrame.append('side')\n",
    "        else:\n",
    "            predictFrame.append('upwards')\n",
    "\n",
    "    # appending the mode of predictions in predict list to assign the tag to the video\n",
    "    predict.append(s.mode(predictFrame)[0][0])\n",
    "    \n",
    "    # appending the actual tag of the video\n",
    "    actual.append(train['label'].loc[train['NameOfFile'] == videoFile].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the accuracy of the predicted tags\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['side',\n",
       " 'front',\n",
       " 'downwards',\n",
       " 'front',\n",
       " 'side',\n",
       " 'side',\n",
       " 'front',\n",
       " 'side',\n",
       " 'downwards',\n",
       " 'front',\n",
       " 'side',\n",
       " 'downwards',\n",
       " 'side',\n",
       " 'downwards',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'downwards',\n",
       " 'side',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'side',\n",
       " 'side']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['side',\n",
       " 'front',\n",
       " 'downwards',\n",
       " 'front',\n",
       " 'side',\n",
       " 'side',\n",
       " 'front',\n",
       " 'side',\n",
       " 'downwards',\n",
       " 'front',\n",
       " 'side',\n",
       " 'downwards',\n",
       " 'side',\n",
       " 'downwards',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'downwards',\n",
       " 'side',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'side',\n",
       " 'side']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model by looking at Frame prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in test labels for verification later\n",
    "train = pd.read_csv('material/test_labels.csv', sep=';')\n",
    "\n",
    "# creating the dummy tags\n",
    "trainLabel = pd.read_csv('material/train_frames.csv')\n",
    "y = trainLabel['class']\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:11<00:00,  2.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# create all frames and csv with labels and frame name\n",
    "\n",
    "# clear temp folder\n",
    "files = glob('temp/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "frameFileNames = []\n",
    "frameFileLabels = []\n",
    "\n",
    "# for loop to extract frames from each test video\n",
    "for i in tqdm(range(train['NameOfFile'].shape[0])):\n",
    "    count = 0\n",
    "    videoFile = train['NameOfFile'][i]\n",
    "    cap = cv2.VideoCapture('material/raw_test_videos/'+videoFile)   # capturing the video from the given path\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    x=1\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1) #current frame number\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        else:\n",
    "            filename ='temp/' + videoFile + \"_frame%d.jpg\" % count;count+=1\n",
    "            frameFileNames.append(filename)\n",
    "            frameFileLabels.append(train['label'][i])\n",
    "            cv2.imwrite(filename, frame)\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "# storing the images and their labels in a dataframe\n",
    "test_frames = pd.DataFrame()\n",
    "test_frames['image'] = frameFileNames\n",
    "test_frames['label'] = frameFileLabels\n",
    "\n",
    "# converting the dataframe into csv file \n",
    "test_frames.to_csv('temp/test_frames.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predicitons on all frames\n",
    "\n",
    "\n",
    "# creating two lists to store predicted and actual tags\n",
    "predictFrame = []\n",
    "actualFrame = []\n",
    "frameName = []\n",
    "\n",
    "# reading all the frames from temp folder\n",
    "images = glob(\"temp/*.jpg\")\n",
    "\n",
    "# reading actual labels from temp folder\n",
    "train = pd.read_csv('temp/test_frames.csv')\n",
    "\n",
    "# open all frames and convert to np array\n",
    "prediction_images = []\n",
    "for i in range(len(images)):\n",
    "    img = image.load_img(images[i], target_size=(480, 640, 3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/480\n",
    "    prediction_images.append(img)\n",
    "    actualFrame.append(train['label'].loc[train['image'] == images[i]].values[0])\n",
    "    frameName.append(images[i].split('/')[1])\n",
    "\n",
    "# converting all the frames for a test video into numpy array\n",
    "prediction_images = np.array(prediction_images)\n",
    "\n",
    "# predicting tags for each array\n",
    "prediction = (model.predict(prediction_images) > 0.5).astype(\"int32\")\n",
    "for pre in prediction:\n",
    "    if pre[0] == 1:\n",
    "        predictFrame.append('downwards')\n",
    "    elif pre[1] == 1:\n",
    "        predictFrame.append('front')\n",
    "    elif pre[2] == 1:\n",
    "        predictFrame.append('side')\n",
    "    else:\n",
    "        predictFrame.append('upwards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame 72 side front\n",
      "frame 79 front side\n",
      "frame 198 front side\n",
      "frame 264 front side\n",
      "frame 277 front side\n",
      "frame 308 front side\n",
      "frame 357 front side\n",
      "frame 368 front side\n",
      "frame 390 front side\n",
      "frame 527 side front\n",
      "frame 553 front side\n",
      "frame 560 front side\n",
      "frame 605 upwards side\n",
      "frame 876 front side\n",
      "frame 909 front side\n",
      "frame 965 front side\n",
      "frame 1228 front side\n",
      "frame 1292 front side\n",
      "frame 1427 front side\n",
      "frame 1622 front side\n",
      "frame 1632 front side\n",
      "frame 1634 front side\n",
      "frame 1653 front side\n",
      "frame 1703 front side\n",
      "frame 1726 front side\n",
      "frame 1774 side front\n",
      "frame 1782 front side\n",
      "frame 1871 front side\n",
      "frame 1872 front side\n",
      "frame 1943 front side\n",
      "frame 2050 front side\n",
      "frame 2071 front side\n",
      "frame 2087 upwards side\n",
      "frame 2096 front side\n",
      "frame 2146 front side\n",
      "Test Accuracy 98.44%\n"
     ]
    }
   ],
   "source": [
    "# checking predicted and actual frames labels which dont match\n",
    "count_corrcet = 0\n",
    "count_false = 0\n",
    "for i in range(0, len(predictFrame)):\n",
    "    if predictFrame[i] == actualFrame[i]:\n",
    "        count_corrcet +=1\n",
    "    else:\n",
    "        print('frame ' + str(i),predictFrame[i], actualFrame[i])\n",
    "        #print(frameName[i])\n",
    "        count_false +=1\n",
    "\n",
    "test_acc = (count_corrcet / (count_corrcet + count_false)) *100\n",
    "print('Test Accuracy {:.2f}%'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate single Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear temp folder\n",
    "files = glob('temp/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "# extract frames from the video and store them\n",
    "count = 0\n",
    "#videoFile = '_tigfCJFLZg_00214.mp4' # should be \"downwards\" but is \"front\"\n",
    "#videoFile = '_8Vy3dlHg2w_00001.mp4' # should be \"upwards\" is \"upwards\"\n",
    "#videoFile = '3PLiUG_DuC8_00346.mp4' # should be \"upwards\" but is \"downwards\"\n",
    "#videoFile = '_tigfCJFLZg_00181.mp4' # should be \"side\" is \"side\"\n",
    "videoFile = 'Video_62.mp4' # should be \"front\" but includes camera switch\n",
    "cap = cv2.VideoCapture('material/single_videos/'+videoFile)   # capturing the video from the given path\n",
    "frameRate = cap.get(5) #frame rate\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    else:\n",
    "        filename ='temp/' + videoFile + \"_frame%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "\n",
    "# creating two lists to store predicted and actual tags\n",
    "predictFrame = []\n",
    "\n",
    "# reading all the frames from temp folder\n",
    "images = glob(\"temp/*.jpg\")\n",
    "\n",
    "# open all frames and convert to np array\n",
    "prediction_images = []\n",
    "for i in range(len(images)):\n",
    "    img = image.load_img(images[i], target_size=(480, 640, 3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/480\n",
    "    prediction_images.append(img)\n",
    "\n",
    "# converting all the frames for a test video into numpy array\n",
    "prediction_images = np.array(prediction_images)\n",
    "\n",
    "# predicting tags for each array\n",
    "prediction = (model.predict(prediction_images) > 0.5).astype(\"int32\")\n",
    "for pre in prediction:\n",
    "    if pre[0] == 1:\n",
    "        predictFrame.append('downwards')\n",
    "    elif pre[1] == 1:\n",
    "        predictFrame.append('front')\n",
    "    elif pre[2] == 1:\n",
    "        predictFrame.append('side')\n",
    "    else:\n",
    "        predictFrame.append('upwards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'side',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'side',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'side',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'upwards',\n",
       " 'front',\n",
       " 'side',\n",
       " 'side']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'front'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#most labels say:\n",
    "s.mode(predictFrame)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  193 false:  47\n"
     ]
    }
   ],
   "source": [
    "# checking predicted and actual frames labels which dont match\n",
    "counterA = 0\n",
    "counterB = 0\n",
    "for i in range(0, len(predictFrame)):\n",
    "    if predictFrame[i] == 'front':\n",
    "        counterA +=1\n",
    "    else:\n",
    "        counterB +=1 \n",
    "print('correct: ', counterA, 'false: ',counterB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
